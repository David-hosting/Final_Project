{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Models for my Final Project - \"IntelliFleetManager\"**"
   ],
   "metadata": {
    "id": "mI9uBPsJ29HB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nni636GJnLCk",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# For organizing the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# For model 1 + 2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# For model 3\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('obd2data.csv')"
   ],
   "metadata": {
    "id": "OikiQunJpjLj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#"
   ],
   "metadata": {
    "id": "k40OhDzpxiA2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Model 1 : Predicts if there is an issue or not**"
   ],
   "metadata": {
    "id": "yF27SNPu3JtP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#"
   ],
   "metadata": {
    "id": "loANeyYO4r3l"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the data into training and testing sets\n",
    "X1 = data.drop(['issues','trouble_codes','time','vehicle_id','id','ip'], axis=1).values\n",
    "y1 = data['issues'].values\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "YWvoqJc2pjDA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(X1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zwdkhrcop1CY",
    "outputId": "00baaaaa-4328-428e-afd0-f5614ff4408d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 8.000e+01  3.330e-01  1.009e+03 ...  0.000e+00  2.510e-01  5.690e-01]\n",
      " [ 8.000e+01  3.250e-01  1.003e+03 ...  0.000e+00  2.510e-01  5.650e-01]\n",
      " [ 8.000e+01  3.290e-01  9.950e+02 ...  0.000e+00  2.510e-01  5.730e-01]\n",
      " ...\n",
      " [-1.000e+00 -1.000e+00 -1.000e+00 ...  0.000e+00 -1.000e+00 -1.000e+00]\n",
      " [-1.000e+00 -1.000e+00 -1.000e+00 ...  0.000e+00 -1.000e+00 -1.000e+00]\n",
      " [-1.000e+00 -1.000e+00 -1.000e+00 ...  0.000e+00 -1.000e+00 -1.000e+00]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(y1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPmKKI-8p2fU",
    "outputId": "1a8b0cc5-95d1-4772-cc03-bf40813fd7f1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Build a neural network model\n",
    "model1 = tf.keras.Sequential([\n",
    "tf.keras.layers.Dense(64, input_shape=(X_train1.shape[1],), activation='relu'),\n",
    "tf.keras.layers.Dense(32, activation='relu'),\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "metadata": {
    "id": "vfW4rGP4pizs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compile the model\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "9atpyXD7ppHi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "model1.fit(X_train1, y_train1, epochs=120, batch_size=32, verbose=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTZ8jdf5prGj",
    "outputId": "7c45c32b-a813-4f60-d70f-e277dafb12bc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 1.8900 - accuracy: 0.7617\n",
      "Epoch 2/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.8153 - accuracy: 0.8015\n",
      "Epoch 3/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.5809 - accuracy: 0.8328\n",
      "Epoch 4/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.5881 - accuracy: 0.8422\n",
      "Epoch 5/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.5496 - accuracy: 0.8495\n",
      "Epoch 6/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.4964 - accuracy: 0.8618\n",
      "Epoch 7/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.5114 - accuracy: 0.8628\n",
      "Epoch 8/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.4154 - accuracy: 0.8695\n",
      "Epoch 9/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.3785 - accuracy: 0.8799\n",
      "Epoch 10/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.3471 - accuracy: 0.8865\n",
      "Epoch 11/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.3193 - accuracy: 0.8916\n",
      "Epoch 12/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.3199 - accuracy: 0.8942\n",
      "Epoch 13/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2972 - accuracy: 0.8949\n",
      "Epoch 14/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.2896 - accuracy: 0.8966\n",
      "Epoch 15/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2819 - accuracy: 0.8976\n",
      "Epoch 16/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2735 - accuracy: 0.9068\n",
      "Epoch 17/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2815 - accuracy: 0.8977\n",
      "Epoch 18/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2350 - accuracy: 0.9091\n",
      "Epoch 19/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.2283 - accuracy: 0.9072\n",
      "Epoch 20/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.2246 - accuracy: 0.9098\n",
      "Epoch 21/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2278 - accuracy: 0.9094\n",
      "Epoch 22/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2176 - accuracy: 0.9097\n",
      "Epoch 23/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2104 - accuracy: 0.9141\n",
      "Epoch 24/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.2051 - accuracy: 0.9179\n",
      "Epoch 25/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1956 - accuracy: 0.9212\n",
      "Epoch 26/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1969 - accuracy: 0.9229\n",
      "Epoch 27/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1975 - accuracy: 0.9195\n",
      "Epoch 28/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1903 - accuracy: 0.9247\n",
      "Epoch 29/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1813 - accuracy: 0.9286\n",
      "Epoch 30/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1828 - accuracy: 0.9277\n",
      "Epoch 31/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1813 - accuracy: 0.9290\n",
      "Epoch 32/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1862 - accuracy: 0.9249\n",
      "Epoch 33/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1745 - accuracy: 0.9319\n",
      "Epoch 34/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1789 - accuracy: 0.9300\n",
      "Epoch 35/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1786 - accuracy: 0.9312\n",
      "Epoch 36/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1717 - accuracy: 0.9339\n",
      "Epoch 37/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1743 - accuracy: 0.9333\n",
      "Epoch 38/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1694 - accuracy: 0.9356\n",
      "Epoch 39/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1748 - accuracy: 0.9321\n",
      "Epoch 40/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1705 - accuracy: 0.9339\n",
      "Epoch 41/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1658 - accuracy: 0.9370\n",
      "Epoch 42/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1671 - accuracy: 0.9350\n",
      "Epoch 43/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1668 - accuracy: 0.9359\n",
      "Epoch 44/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1596 - accuracy: 0.9395\n",
      "Epoch 45/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1604 - accuracy: 0.9390\n",
      "Epoch 46/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1656 - accuracy: 0.9353\n",
      "Epoch 47/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1610 - accuracy: 0.9363\n",
      "Epoch 48/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1650 - accuracy: 0.9352\n",
      "Epoch 49/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1584 - accuracy: 0.9384\n",
      "Epoch 50/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1598 - accuracy: 0.9375\n",
      "Epoch 51/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1543 - accuracy: 0.9391\n",
      "Epoch 52/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1491 - accuracy: 0.9428\n",
      "Epoch 53/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1522 - accuracy: 0.9400\n",
      "Epoch 54/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.1511 - accuracy: 0.9417\n",
      "Epoch 55/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1500 - accuracy: 0.9416\n",
      "Epoch 56/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1500 - accuracy: 0.9421\n",
      "Epoch 57/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1485 - accuracy: 0.9430\n",
      "Epoch 58/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1457 - accuracy: 0.9429\n",
      "Epoch 59/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1490 - accuracy: 0.9418\n",
      "Epoch 60/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1490 - accuracy: 0.9423\n",
      "Epoch 61/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1451 - accuracy: 0.9431\n",
      "Epoch 62/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1452 - accuracy: 0.9442\n",
      "Epoch 63/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1481 - accuracy: 0.9430\n",
      "Epoch 64/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1478 - accuracy: 0.9419\n",
      "Epoch 65/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1432 - accuracy: 0.9446\n",
      "Epoch 66/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1477 - accuracy: 0.9420\n",
      "Epoch 67/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1414 - accuracy: 0.9454\n",
      "Epoch 68/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1459 - accuracy: 0.9425\n",
      "Epoch 69/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1444 - accuracy: 0.9448\n",
      "Epoch 70/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1466 - accuracy: 0.9419\n",
      "Epoch 71/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.1405 - accuracy: 0.9460\n",
      "Epoch 72/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1411 - accuracy: 0.9467\n",
      "Epoch 73/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1454 - accuracy: 0.9430\n",
      "Epoch 74/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1393 - accuracy: 0.9470\n",
      "Epoch 75/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1446 - accuracy: 0.9431\n",
      "Epoch 76/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1414 - accuracy: 0.9459\n",
      "Epoch 77/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1417 - accuracy: 0.9443\n",
      "Epoch 78/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1399 - accuracy: 0.9462\n",
      "Epoch 79/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1442 - accuracy: 0.9433\n",
      "Epoch 80/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1420 - accuracy: 0.9467\n",
      "Epoch 81/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1431 - accuracy: 0.9447\n",
      "Epoch 82/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1412 - accuracy: 0.9460\n",
      "Epoch 83/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1406 - accuracy: 0.9452\n",
      "Epoch 84/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1406 - accuracy: 0.9465\n",
      "Epoch 85/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1406 - accuracy: 0.9457\n",
      "Epoch 86/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1408 - accuracy: 0.9457\n",
      "Epoch 87/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1403 - accuracy: 0.9441\n",
      "Epoch 88/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1370 - accuracy: 0.9483\n",
      "Epoch 89/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1384 - accuracy: 0.9462\n",
      "Epoch 90/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1378 - accuracy: 0.9475\n",
      "Epoch 91/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1382 - accuracy: 0.9482\n",
      "Epoch 92/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1388 - accuracy: 0.9471\n",
      "Epoch 93/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1377 - accuracy: 0.9489\n",
      "Epoch 94/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.1372 - accuracy: 0.9478\n",
      "Epoch 95/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1342 - accuracy: 0.9491\n",
      "Epoch 96/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1372 - accuracy: 0.9479\n",
      "Epoch 97/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1377 - accuracy: 0.9471\n",
      "Epoch 98/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1346 - accuracy: 0.9492\n",
      "Epoch 99/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.1348 - accuracy: 0.9488\n",
      "Epoch 100/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.1348 - accuracy: 0.9488\n",
      "Epoch 101/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1339 - accuracy: 0.9484\n",
      "Epoch 102/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1344 - accuracy: 0.9486\n",
      "Epoch 103/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1330 - accuracy: 0.9501\n",
      "Epoch 104/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1319 - accuracy: 0.9493\n",
      "Epoch 105/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1342 - accuracy: 0.9491\n",
      "Epoch 106/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1318 - accuracy: 0.9507\n",
      "Epoch 107/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1335 - accuracy: 0.9492\n",
      "Epoch 108/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1314 - accuracy: 0.9512\n",
      "Epoch 109/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1323 - accuracy: 0.9501\n",
      "Epoch 110/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1301 - accuracy: 0.9509\n",
      "Epoch 111/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1327 - accuracy: 0.9490\n",
      "Epoch 112/120\n",
      "1184/1184 [==============================] - 3s 3ms/step - loss: 0.1345 - accuracy: 0.9497\n",
      "Epoch 113/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1289 - accuracy: 0.9517\n",
      "Epoch 114/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1311 - accuracy: 0.9500\n",
      "Epoch 115/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1310 - accuracy: 0.9492\n",
      "Epoch 116/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1285 - accuracy: 0.9524\n",
      "Epoch 117/120\n",
      "1184/1184 [==============================] - 4s 3ms/step - loss: 0.1305 - accuracy: 0.9507\n",
      "Epoch 118/120\n",
      "1184/1184 [==============================] - 3s 2ms/step - loss: 0.1292 - accuracy: 0.9517\n",
      "Epoch 119/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1280 - accuracy: 0.9520\n",
      "Epoch 120/120\n",
      "1184/1184 [==============================] - 2s 2ms/step - loss: 0.1305 - accuracy: 0.9509\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5d102d6460>"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the performance of the model\n",
    "loss1, accuracy1 = model1.evaluate(X_test1, y_test1)\n",
    "print('Accuracy:', accuracy1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTWRIOuQpsh2",
    "outputId": "8b634dec-7c5e-408d-ed35-f462a9a30766"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "296/296 [==============================] - 25s 1ms/step - loss: 0.1471 - accuracy: 0.9418\n",
      "Accuracy: 0.9417978525161743\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = model1.predict(X_test1)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "print(y_pred)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHdoXgdZjcVz",
    "outputId": "07bef7fa-9aef-49d6-ae71-3ee19c54f656"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "296/296 [==============================] - 0s 1ms/step\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#"
   ],
   "metadata": {
    "id": "cpPiK_X_4191"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Model 2 : Predicts which issue**"
   ],
   "metadata": {
    "id": "vYgPvrh743SU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#"
   ],
   "metadata": {
    "id": "hx5_wzn6wane"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Filter the dataset to include only rows where \"issues\" equals 1\n",
    "X2 = data[data['issues'] == 1].copy()\n",
    "\n",
    "# Make a y2 data based on X2\n",
    "temp_y2 = X2['trouble_codes'].values\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "temp_y2 = one_hot_encoder.fit_transform(temp_y2.reshape(-1, 1))\n",
    "y2 = np.argmax(temp_y2, axis=1)  # Convert one-hot encoded labels to integer labels\n",
    "\n",
    "# Drop the noneed columns from X2\n",
    "X2.drop(['issues', 'trouble_codes', 'time', 'vehicle_id', 'id', 'ip'], axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "qcisJtCOzwUj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42) \n",
    "\n",
    "# Make num_categories for the number of the trouble codes we have in our y_train2\n",
    "num_categories = len(np.unique(y_train2))"
   ],
   "metadata": {
    "id": "x5BipwKmwa8s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(y_train2.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kKqkPT34wvQS",
    "outputId": "fc82e594-e584-44c5-8fd3-181c3aeb8d70"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(9540,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(X_train2.shape[1])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeoduFfGDPH6",
    "outputId": "7349671a-adca-47d6-b43e-2b9242f2639c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(num_categories)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PrR93yJ2JmO",
    "outputId": "3e2c7168-1b77-4f8c-f51e-80c9ca1737df"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(X_train2.shape[1],), activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_categories, activation='softmax')\n",
    "])\n"
   ],
   "metadata": {
    "id": "Fbl-jxQ4wwZG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model2.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HzB63QgDvUP",
    "outputId": "e1c2c445-e1a3-4aa8-ea7c-b2fe0ea85bd2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 64)                704       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 13)                429       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,213\n",
      "Trainable params: 3,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Compile the model\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "v3-L0jt0xFUy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "model2.fit(X_train2, y_train2, epochs=120, batch_size=32, verbose=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkq69u4yxJ80",
    "outputId": "52b9ea1a-6157-4865-91d6-70197db2c077"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 10.0209 - accuracy: 0.4993\n",
      "Epoch 2/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.7582 - accuracy: 0.5415\n",
      "Epoch 3/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.9049 - accuracy: 0.5522\n",
      "Epoch 4/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.3737 - accuracy: 0.5543\n",
      "Epoch 5/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.4761 - accuracy: 0.5581\n",
      "Epoch 6/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 1.3184 - accuracy: 0.5805\n",
      "Epoch 7/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1995 - accuracy: 0.5926\n",
      "Epoch 8/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1058 - accuracy: 0.6034\n",
      "Epoch 9/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1217 - accuracy: 0.5927\n",
      "Epoch 10/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1898 - accuracy: 0.6027\n",
      "Epoch 11/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.0980 - accuracy: 0.6081\n",
      "Epoch 12/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1402 - accuracy: 0.6080\n",
      "Epoch 13/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1411 - accuracy: 0.6100\n",
      "Epoch 14/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.0452 - accuracy: 0.6312\n",
      "Epoch 15/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.0242 - accuracy: 0.6327\n",
      "Epoch 16/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.0721 - accuracy: 0.6308\n",
      "Epoch 17/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.9414 - accuracy: 0.6504\n",
      "Epoch 18/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.0011 - accuracy: 0.6258\n",
      "Epoch 19/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.1570 - accuracy: 0.6268\n",
      "Epoch 20/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 1.0922 - accuracy: 0.6154\n",
      "Epoch 21/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.8290 - accuracy: 0.6633\n",
      "Epoch 22/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.9383 - accuracy: 0.6416\n",
      "Epoch 23/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.8863 - accuracy: 0.6564\n",
      "Epoch 24/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.8224 - accuracy: 0.6737\n",
      "Epoch 25/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.9477 - accuracy: 0.6488\n",
      "Epoch 26/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.9655 - accuracy: 0.6494\n",
      "Epoch 27/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.7865 - accuracy: 0.6917\n",
      "Epoch 28/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.8025 - accuracy: 0.6814\n",
      "Epoch 29/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.8351 - accuracy: 0.6781\n",
      "Epoch 30/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.7719 - accuracy: 0.6867\n",
      "Epoch 31/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.7975 - accuracy: 0.6903\n",
      "Epoch 32/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.7915 - accuracy: 0.6901\n",
      "Epoch 33/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.7088 - accuracy: 0.7161\n",
      "Epoch 34/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.7509 - accuracy: 0.7147\n",
      "Epoch 35/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.8301 - accuracy: 0.6990\n",
      "Epoch 36/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6700 - accuracy: 0.7382\n",
      "Epoch 37/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.7343 - accuracy: 0.7062\n",
      "Epoch 38/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6748 - accuracy: 0.7490\n",
      "Epoch 39/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6993 - accuracy: 0.7311\n",
      "Epoch 40/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6215 - accuracy: 0.7653\n",
      "Epoch 41/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6406 - accuracy: 0.7588\n",
      "Epoch 42/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6371 - accuracy: 0.7698\n",
      "Epoch 43/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.7754\n",
      "Epoch 44/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6176 - accuracy: 0.7616\n",
      "Epoch 45/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.6430 - accuracy: 0.7416\n",
      "Epoch 46/120\n",
      "299/299 [==============================] - 1s 4ms/step - loss: 0.6275 - accuracy: 0.7644\n",
      "Epoch 47/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.6628 - accuracy: 0.7413\n",
      "Epoch 48/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.6758 - accuracy: 0.7189\n",
      "Epoch 49/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.7959 - accuracy: 0.5955\n",
      "Epoch 50/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.6354 - accuracy: 0.7507\n",
      "Epoch 51/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6427 - accuracy: 0.7411\n",
      "Epoch 52/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6282 - accuracy: 0.7571\n",
      "Epoch 53/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5743 - accuracy: 0.7798\n",
      "Epoch 54/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.6202 - accuracy: 0.7548\n",
      "Epoch 55/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.7695\n",
      "Epoch 56/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7980\n",
      "Epoch 57/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7806\n",
      "Epoch 58/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7904\n",
      "Epoch 59/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7945\n",
      "Epoch 60/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7907\n",
      "Epoch 61/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7993\n",
      "Epoch 62/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7930\n",
      "Epoch 63/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5107 - accuracy: 0.8079\n",
      "Epoch 64/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4984 - accuracy: 0.8194\n",
      "Epoch 65/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5218 - accuracy: 0.8001\n",
      "Epoch 66/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7940\n",
      "Epoch 67/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4914 - accuracy: 0.8123\n",
      "Epoch 68/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4820 - accuracy: 0.8212\n",
      "Epoch 69/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.8090\n",
      "Epoch 70/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.5009 - accuracy: 0.8090\n",
      "Epoch 71/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.5052 - accuracy: 0.8077\n",
      "Epoch 72/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5181 - accuracy: 0.7978\n",
      "Epoch 73/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.8170\n",
      "Epoch 74/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.8166\n",
      "Epoch 75/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5265 - accuracy: 0.7997\n",
      "Epoch 76/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.8181\n",
      "Epoch 77/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.5004 - accuracy: 0.8145\n",
      "Epoch 78/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.8213\n",
      "Epoch 79/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4928 - accuracy: 0.8118\n",
      "Epoch 80/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4774 - accuracy: 0.8214\n",
      "Epoch 81/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4875 - accuracy: 0.8192\n",
      "Epoch 82/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.8188\n",
      "Epoch 83/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4609 - accuracy: 0.8318\n",
      "Epoch 84/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4875 - accuracy: 0.8155\n",
      "Epoch 85/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4636 - accuracy: 0.8288\n",
      "Epoch 86/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8251\n",
      "Epoch 87/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4751 - accuracy: 0.8188\n",
      "Epoch 88/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4578 - accuracy: 0.8295\n",
      "Epoch 89/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.8204\n",
      "Epoch 90/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.8286\n",
      "Epoch 91/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4708 - accuracy: 0.8253\n",
      "Epoch 92/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4646 - accuracy: 0.8288\n",
      "Epoch 93/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.8166\n",
      "Epoch 94/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4523 - accuracy: 0.8370\n",
      "Epoch 95/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4703 - accuracy: 0.8263\n",
      "Epoch 96/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8289\n",
      "Epoch 97/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.8361\n",
      "Epoch 98/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.8339\n",
      "Epoch 99/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4481 - accuracy: 0.8335\n",
      "Epoch 100/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.8339\n",
      "Epoch 101/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8448\n",
      "Epoch 102/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4701 - accuracy: 0.8285\n",
      "Epoch 103/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.8379\n",
      "Epoch 104/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4450 - accuracy: 0.8435\n",
      "Epoch 105/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8331\n",
      "Epoch 106/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4581 - accuracy: 0.8330\n",
      "Epoch 107/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.8408\n",
      "Epoch 108/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4446 - accuracy: 0.8407\n",
      "Epoch 109/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.8441\n",
      "Epoch 110/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4260 - accuracy: 0.8449\n",
      "Epoch 111/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4268 - accuracy: 0.8500\n",
      "Epoch 112/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4356 - accuracy: 0.8466\n",
      "Epoch 113/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4569 - accuracy: 0.8306\n",
      "Epoch 114/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4432 - accuracy: 0.8379\n",
      "Epoch 115/120\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 0.4325 - accuracy: 0.8477\n",
      "Epoch 116/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4447 - accuracy: 0.8357\n",
      "Epoch 117/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8422\n",
      "Epoch 118/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4447 - accuracy: 0.8407\n",
      "Epoch 119/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.8481\n",
      "Epoch 120/120\n",
      "299/299 [==============================] - 1s 2ms/step - loss: 0.4461 - accuracy: 0.8362\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5d12588970>"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluate the performance of the model\n",
    "loss2, accuracy2 = model2.evaluate(X_test2, y_test2)\n",
    "print('Accuracy:', accuracy2)"
   ],
   "metadata": {
    "id": "_XDnCmmXxLJX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "16b14ea3-619f-41df-ed38-e2ebf522fa25"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8780\n",
      "Accuracy: 0.8779874444007874\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#"
   ],
   "metadata": {
    "id": "IwmVVA9oxUhj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Model 3 : Predicts which issue will appear next**"
   ],
   "metadata": {
    "id": "LBm9d9jrAXcu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#"
   ],
   "metadata": {
    "id": "kxn1Fc1yAZJy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Filter for rows where \"issues\" == 1\n",
    "filtered_data = data[data[\"issues\"] == 1].copy()\n",
    "\n",
    "# Create a pivot table to get all unique trouble codes for each car ID\n",
    "pivot_table = filtered_data.pivot_table(index=[\"vehicle_id\"], values=[\"trouble_codes\"], aggfunc=lambda x: tuple(np.unique(x)))\n",
    "\n",
    "# Convert the pivot table to a NumPy array\n",
    "trouble_data = pivot_table.to_numpy()"
   ],
   "metadata": {
    "id": "GtN5ssBSBKJd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Print the list of arrays\n",
    "print(trouble_data)"
   ],
   "metadata": {
    "id": "HUxIhVWHC67e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "29f5a20c-8dbb-463a-9f79-6941761534e9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[('P0133',)]\n",
      " [('P0133',)]\n",
      " [('P0133',)]\n",
      " [('C0300',)]\n",
      " [('C0300',)]\n",
      " [('P0078B0004P3000', 'P0078U1004P3000', 'P0079C1004P3000', 'P0079P1004P3000', 'P0079P2004P3000', 'P007EP2036P18D0', 'P007EP2036P18E0', 'P007EP2036P18F0', 'P007FP2036P18D0', 'P007FP2036P18E0', 'P007FP2036P18F0')]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Convert the dataset into a pandas DataFrame\n",
    "dataset = pd.DataFrame(trouble_data)\n",
    "dataset"
   ],
   "metadata": {
    "id": "Z_0Zb6zQBKFo",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "outputId": "62c7052a-2190-4eb6-9b36-0979f329daa0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   0\n",
       "0                                           (P0133,)\n",
       "1                                           (P0133,)\n",
       "2                                           (P0133,)\n",
       "3                                           (C0300,)\n",
       "4                                           (C0300,)\n",
       "5  (P0078B0004P3000, P0078U1004P3000, P0079C1004P..."
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-b6b2add4-8a9e-4b36-89f9-ff875f33d4ee\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(P0133,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(P0133,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(P0133,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(C0300,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(C0300,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(P0078B0004P3000, P0078U1004P3000, P0079C1004P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6b2add4-8a9e-4b36-89f9-ff875f33d4ee')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b6b2add4-8a9e-4b36-89f9-ff875f33d4ee button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b6b2add4-8a9e-4b36-89f9-ff875f33d4ee');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Transform the dataset into a one-hot encoded matrix\n",
    "onehot = pd.get_dummies(dataset.apply(pd.Series).stack()).sum(level=0)"
   ],
   "metadata": {
    "id": "4jU9YLMkBKCF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8f640067-802b-4b7c-ff6b-6a6155cae835"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-152-cad5a7d33352>:2: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
      "  onehot = pd.get_dummies(dataset.apply(pd.Series).stack()).sum(level=0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate frequent itemsets using the Apriori algorithm\n",
    "frequent_itemsets = apriori(onehot, min_support=0.3, use_colnames=True)"
   ],
   "metadata": {
    "id": "v_mUdTfXBJ_F"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Generate association rules from frequent itemsets\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)"
   ],
   "metadata": {
    "id": "loGK4WG-BJ7f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Print the association rules\n",
    "print(rules)"
   ],
   "metadata": {
    "id": "GU5mN7wvBJxS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c906d2b6-e979-446f-9ce4-6bac6143e424"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction]\n",
      "Index: []\n"
     ]
    }
   ]
  }
 ]
}
